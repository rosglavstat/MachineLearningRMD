Practical Machine Learning Course Project
========================================================
## Wearable devices. Measuring quality instead of quantity. 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

Source data for the project is recieved from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal of the project is to predict the manner in which they did the exercise using the data from the accelerometers and other available in the dataset.

### Code and comments

We model and predict using functions from the caret package
```{r, results="hide", message=FALSE, warning=FALSE}
library(caret)
```

To keep the research reproducible the links to the source data are added to the document.
```{r, cache=TRUE}
#Download data file from the web
fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl, destfile = "./data/pml-training.csv", method = "curl")

fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl, destfile = "./data/pml-testing.csv", method = "curl")

#Read data to dataframe
training_dataset <- read.csv("./data/pml-training.csv", stringsAsFactors = FALSE)
testing_dataset <- read.csv("./data/pml-testing.csv", stringsAsFactors = FALSE)
```

Primary data preprocessing: 
we substitude "#DIV/0!" expression by NA, select only numeric columns and make sure all data in them is numeric.

```{r, results="hide", message=FALSE, warning=FALSE}
training_dataset[training_dataset=="#DIV/0!"] = NA
training_short <- training_dataset[c(-1,-2,-3,-4,-5,-6,-160)]
training_num <- sapply(training_short, as.numeric)
training <- data.frame(training_dataset[160], training_num)
```

Next step - remove all columns, containg more than 1000 NAs 
(for this dataframe it just removes all columns with NAs)
```{r, results="hide", message=FALSE, warning=FALSE}
nacols <- sapply(training, function(x) { length(which(is.na(x))) })
logcols <- nacols < 1000
shtrain <- training [logcols]
```

Adding a numeric variable
```{r, results="hide", message=FALSE, warning=FALSE}
shtrain$classe <- as.factor(shtrain$classe)
shtrain$classe_num <- as.numeric(shtrain$classe)
```

Select 20% of the full sample to experiment with the data
```{r, results="hide", message=FALSE, warning=FALSE}
inTrain <- createDataPartition(y=shtrain$classe, p=0.2, list=FALSE)
train_final <- shtrain[inTrain,-1]
```

Build a general linear model predicting the numeric variable, corresponding to the factor variable we want to predict.
We do this as while have too many predictors we want to run a "cheap"" algorithm. 
```{r, results="hide", message=FALSE, warning=FALSE, cache=TRUE}
modelFit <- train(classe_num ~., data=train_final, method="glm")
```

The model built helps us to identify the most important variables
```{r}
varImp(modelFit)
```

Create a new dataframe, that contains only main variables.
```{r, results="hide", message=FALSE, warning=FALSE}
train_fin_20 <- shtrain[inTrain,c("classe","magnet_dumbbell_z","accel_forearm_z","magnet_dumbbell_x","yaw_dumbbell","accel_arm_z","pitch_forearm","accel_belt_y","magnet_belt_y","accel_dumbbell_x","total_accel_forearm","pitch_belt","roll_dumbbell","pitch_arm","roll_belt","magnet_forearm_x","total_accel_arm","magnet_forearm_y","yaw_belt","gyros_dumbbell_y")]
```                                
    
Apply random forest algorithm
```{r, results="hide", message=FALSE, warning=FALSE, cache=TRUE}
modelFit <- train(classe ~ ., data=train_fin_20, method="rf")
```  

### Cross validation

Prepare the testing set and apply the model to it
```{r results="hide", message=FALSE, warning=FALSE, cache=TRUE}
testing <- shtrain[-inTrain,]
predictions <- predict(modelFit,newdata=testing)
``` 

Show confusion matrix
```{r}
confusionMatrix(testing$classe, predict(modelFit,newdata=testing))
``` 

#### Accuracy : 0.9634
#### Out of sample error: 0.0366
